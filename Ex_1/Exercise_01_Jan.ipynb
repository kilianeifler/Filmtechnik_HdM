{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exercise:\n",
    "\n",
    "## 1.1. Introduction and Imports\n",
    "\n",
    "- Load Exercise_01_Template.ipynb\n",
    "- Save this file as Exercise_01_Group_xx.ipynb where xx is your group number.\n",
    "- Put your Group number and your names in the first paragraph of the file.\n",
    "- Groups have to have at least 2 members and a maximum of 3 members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Number: xx\n",
    "# Group Members: xx xx, yy yy, (zz zz) \n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import numpy.matlib as ml\n",
    "import imageio\n",
    "import skimage.transform\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline\n",
    "# Set default figure size as plots and images are displayed very small otherwise (parameters are intended to represent width and height in inches)\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Load and display an image\n",
    "- Load the image Exercise_01_Peppers.png into Python and display it\n",
    "- The result should look as follows:\n",
    "\n",
    "<img src=\"Exercise_01_Result_1_2.png\" alt=\"Result\" style=\"width: 256px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read \"Exercise_01_Peppers.png\"\n",
    "peppersImg = plt.imread('Exercise_01_Peppers.png') #R peppersImg = # Your code here\n",
    "\n",
    "# Plot peppersImg\n",
    "plt.imshow( peppersImg ) #R # Your code here\n",
    "\n",
    "# Output image size\n",
    "peppersImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By the way - how do I find methods like 'shape'?\n",
    "dir( peppersImg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cool, let's try some:\n",
    "print( \"Max: \" + str( peppersImg.max()  ) )\n",
    "print( \"Min: \" + str( peppersImg.min()  ) )\n",
    "print( \"Mean: \" + str( peppersImg.mean() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Let's play with indexing - display a white square and circle on black background\n",
    "- Create a black image with a white square in the middle by using indexing.\n",
    "- The result should look as follows:\n",
    "\n",
    "<img src=\"Exercise_01_Result_1_3_Square.png\" alt=\"Result\" style=\"width: 256px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Black image of size 200*200 pixel\n",
    "squareImg = np.zeros( (200, 200) )\n",
    "\n",
    "# Add White square\n",
    "squareImg[60:141, 60:141] = 1.0  #R # Your code here\n",
    "\n",
    "# Plot\n",
    "plt.imshow(squareImg, cmap='gray', vmin=0.0, vmax=1.0)\n",
    "squareImg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now do the same but display a white circle\n",
    "- The result should look as follows:\n",
    "\n",
    "<img src=\"Exercise_01_Result_1_3_Circle.png\" alt=\"Result\" style=\"width: 256px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Black image of size 200*200 pixel\n",
    "circleImg = np.zeros( (200, 200) )\n",
    "\n",
    "# Create varable which contain the x and y position in the image\n",
    "xPos = np.tile( np.reshape( np.arange(0,200), ( 200, 1 ) ), [1, 200 ] )\n",
    "yPos = np.tile( np.reshape( np.arange(0,200), ( 1, 200 ) ), [200, 1 ] )\n",
    "\n",
    "# Add awhite circle by setting all pixel inside the circle to 1.0. (Conditional indexing)\n",
    "circleImg[ np.sqrt( np.power(xPos-100.0,2.0) + np.power(yPos-100.0,2.0) ) < 50 ] = 1.0  #R circleImg = # Your code here\n",
    "\n",
    "# Plot\n",
    "plt.imshow(circleImg, cmap='gray', vmin=0.0, vmax=1.0)\n",
    "circleImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Do you have a simple idea how to render a smoother border?\n",
    "circleImg = np.clip( 50 - np.sqrt( np.power(xPos-100.0,2.0) + np.power(yPos-100.0,2.0) ), 0.0, 1.0 ) #R circleImg = # Your code here\n",
    "\n",
    "# Plot\n",
    "plt.imshow(circleImg, cmap='gray', vmin=0.0, vmax=1.0)\n",
    "circleImg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. The sRGB Color Space\n",
    "- Typical images like the file Exercise_01_Peppers.png are stored in sRGB color space.\n",
    "- Load Exercise_01_Peppers.png into the variable img_sRGB.\n",
    "- Add two horizontal gradients below the image, one from 0.4 to 0.6 and one from 0 to 0.1 both in 0…1 sRGB domain. See image on the right for an example.\n",
    "- Display this image with different brightness offsets.\n",
    "- Linearize this file according to the formula given in: https://www.w3.org/Graphics/Color/sRGB.html and save it into a variable called img_Linear.\n",
    "- Display this linearized image. What needs to be done so that it looks correct again?\n",
    "- Display this image at different brightness levels implementing brightness in linear domain.\n",
    "- Is ‘+’ still the correct operation to implement brightness? No! Implement a better operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 128*512 pixel horizontal gradient from 0.4 to 0.6 in 0…1 sRGB domain.\n",
    "gradient1 = np.tile( np.reshape( np.linspace( 0.4, 0.6, 512 ), ( 1, 512, 1 ) ), [128, 1, 3 ] ) #R gradient1 = # Your code here\n",
    "\n",
    "# Plot gradient\n",
    "plt.imshow( gradient1 )\n",
    "gradient1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 128*512 pixel horizontal gradient from 0.0 to 0.1 in 0…1 sRGB domain.\n",
    "gradient2 = np.tile( np.reshape( np.linspace( 0.0, 0.1, 512 ), ( 1, 512, 1 ) ), [128, 1, 3 ] ) #R gradient2 = # Your code here\n",
    "\n",
    "# Load Exercise_01_Peppers.png into the variable peppersImg \n",
    "peppersImg = plt.imread( 'Exercise_01_Peppers.png' ) #R peppersImg = # Your code here\n",
    "\n",
    "# Concatenate all three images\n",
    "img_sRGB = np.concatenate( ( peppersImg, gradient1, gradient2 ), axis=0 )\n",
    "\n",
    "# Plot the combined Image\n",
    "plt.imshow( img_sRGB );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display with different brightness offsets\n",
    "\n",
    "brightness1 = 0.3\n",
    "brightness2 = 0.5\n",
    "brightness3 = 0.8\n",
    "\n",
    "plt.figure(figsize=(16,8))  # Alternative to figsize setting in the first code block\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow( np.clip( img_sRGB + brightness1, 0.0, 1.0) );\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow( np.clip( img_sRGB + brightness2, 0.0, 1.0) );\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow( np.clip( img_sRGB + brightness3, 0.0, 1.0) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now implement the sRGB functions so that we can use them to convert our image to linear domain\n",
    "def linear2sRGB(x):\n",
    "    result = np.zeros(x.shape)                                                          #R # Your code here\n",
    "    result[ x <= 0.0031308 ] = 12.92 * x[ x <= 0.0031308 ]                              #R # Your code here\n",
    "    result[ x >  0.0031308 ] = 1.055 * np.power( x[ x >  0.0031308 ], (1/2.4) ) - 0.055 #R # Your code here\n",
    "    return result\n",
    "\n",
    "def sRGB2linear(x):\n",
    "    result = np.zeros(x.shape)                                                         #R # Your code here\n",
    "    result[ x <= 0.04045 ] = x[ x <= 0.04045 ] / 12.92                                 #R # Your code here\n",
    "    result[ x >  0.04045 ] = np.power( ( ( x[ x > 0.04045 ] + 0.055 ) / 1.055 ), 2.4 ) #R # Your code here\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No let's try to apply '+' as a brightness opaerator in linear domain:\n",
    "brightness1 = 0.2\n",
    "brightness2 = 0.5\n",
    "img_Linear = sRGB2linear( img_sRGB )\n",
    "plt.figure( figsize = (16,8) )  # Alternative to figsize setting in the first code block\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow( np.clip( linear2sRGB( img_Linear + brightness1 ), 0.0, 1.0 ) );\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow( np.clip( linear2sRGB( img_Linear + brightness2 ), 0.0, 1.0 ) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the '+' operator does not work well. Exchange for a better operator and display\n",
    "\n",
    "brightness1 = 1.0                                                           #R # Your code here \n",
    "brightness2 = 1.5                                                           #R # Your code here \n",
    "brightness3 = 4.0                                                           #R # Your code here\n",
    "plt.figure(figsize=(16,8))                                                  #R # Your code here\n",
    "plt.subplot(1,3,1)                                                          #R # Your code here\n",
    "plt.imshow( np.clip( linear2sRGB( img_Linear * brightness1 ), 0.0, 1.0 ) ); #R # Your code here\n",
    "plt.subplot(1,3,2)                                                          #R # Your code here\n",
    "plt.imshow( np.clip( linear2sRGB( img_Linear * brightness2 ), 0.0, 1.0 ) ); #R # Your code here\n",
    "plt.subplot(1,3,3)                                                          #R # Your code here\n",
    "plt.imshow( np.clip( linear2sRGB( img_Linear * brightness3 ), 0.0, 1.0 ) ); #R # Your code here\n",
    "\n",
    "# Please explain your choice of operator in words and why it is a good match to '+' in perceptual domain.\n",
    "#R # Your Explanation here\n",
    "#R # Your Explanation here\n",
    "#R # Your Explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Filtering in linear domain\n",
    "Some operations must be performed in linear domain to get a realistic result.\n",
    "- Load Exercise_01_Playground_c_Timo_Kunkel.exr.\n",
    "- Display the image on your monitor.\n",
    "- Use imfilter with the supplied filter kernel in pq and in linear domain. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions provides read support for OpenEXR files. You only have to execute it once per computer.\n",
    "imageio.plugins.freeimage.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read typical HDR image from disk\n",
    "linImg = imageio.imread(\"Exercise_01_Playground_c_Timo_Kunkel.exr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to sRGB and display\n",
    "sRGBImg = np.clip( linear2sRGB( linImg ), 0.0, 1.0 );\n",
    "plt.imshow( sRGBImg );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a \"nice\" aperture to the image for a 'bokeh-style' effect\n",
    "\n",
    "# Import polygon function\n",
    "from skimage.draw import polygon\n",
    "\n",
    "# Init aperture\n",
    "aperture = np.zeros((40, 40))\n",
    "xPos = np.array([-1, -0.5, 0.5, 1, 0.5, -0.5, -1])*20+20\n",
    "yPos= np.sqrt(3) * np.array([0, -0.5, -0.5, 0, 0.5, 0.5, 0])*20+20\n",
    "xIdx, yIdx = polygon(xPos, yPos)\n",
    "\n",
    "# Set pixels inside polygon to 1\n",
    "aperture[xIdx, yIdx] = 1\n",
    "\n",
    "# Normalize aperture\n",
    "aperture = aperture / np.sum(aperture) #R aperture = # Your code here\n",
    "plt.imshow( aperture );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter in sRGB domain and display\n",
    "convolve_sRGBImg = np.zeros((linImg.shape))\n",
    "for i in range(3):\n",
    "    convolve_sRGBImg[:,:,i] = scipy.ndimage.convolve( sRGBImg[:,:,i], aperture )\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('Filter applied in sRGB nonlinear domain')\n",
    "plt.imshow( convolve_sRGBImg );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter in linear domain and display\n",
    "convolve_linImg = np.zeros((linImg.shape))\n",
    "for i in range(3):\n",
    "    convolve_linImg[:,:,i] = scipy.ndimage.convolve( linImg[:,:,i], aperture )\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title('Filter applied in linear domain')\n",
    "plt.imshow( np.clip( linear2sRGB( convolve_linImg ), 0.0, 1.0 ) );\n",
    "\n",
    "# Explain why the 'Bokeh' Effect can only be simulated in linear domain\n",
    "# Your explanation here\n",
    "# Your explanation here\n",
    "# Your explanation here\n",
    "\n",
    "# Bonus: Play with different apertures, e.g. stars, rings, hearts,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Image quantization\n",
    "Is it meaningful to talk about image quantization without referencing if the image is coded in linear or\n",
    "perceptual domain?\n",
    "- Quantize the image from 1.4. (including the ramps) in both domains, linear and sRGB to bit depths between 4 and 16 bits.\n",
    "- How many bits are needed in each domain for a visually transparent display?\n",
    "- Just for your information: Most DSLRs quantize with 12bits or 14bit in linear sensor domain. Is this better compared to 8bits of tonal resolution in sRGB domain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write formula for quantization\n",
    "def quantize( img,bitDepth ):\n",
    "    return np.round(img * ( np.power( 2, bitDepth-1 ) ) ) / ( np.power( 2, bitDepth-1 ) ) #R return # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What bit-depth is needed for visually tranparent quantization in sRGB domain?\n",
    "# Plot our 'img_sRGB' quantized in sRGB domain quantized to 1...8 bits\n",
    "for bitDepth in range(1,9):\n",
    "    plt.figure(figsize=(15,10))                #R # Your code here\n",
    "    plt.subplot(1,2,1)                         #R # Your code here\n",
    "    plt.title('Original Image')                #R # Your code here\n",
    "    plt.imshow(img_sRGB)                       #R # Your code here\n",
    "    plt.subplot(1,2,2)                         #R # Your code here\n",
    "    plt.title('Bitdepth: ' + str(bitDepth))    #R # Your code here\n",
    "    plt.imshow(quantize(img_sRGB, bitDepth))   #R # Your code here\n",
    "    plt.show()                                 #R # Your code here\n",
    "\n",
    "# What is the nimimun bit-depth that can be used for quantizing the image without artifacts? \n",
    "# Is this the same value for the gradients compared to the image?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What bit-depth is needed for visually tranparent quantization in linear domain?\n",
    "# Plot our 'img_sRGB' quantized in linear domain quantized to 1...16 bits\n",
    "for bitDepth in range(1,17):\n",
    "    plt.figure(figsize=(15,10))                                        #R # Your code here\n",
    "    plt.subplot(1,2,1)                                                 #R # Your code here\n",
    "    plt.title('Original Image')                                        #R # Your code here\n",
    "    plt.imshow(img_sRGB)                                               #R # Your code here\n",
    "    plt.subplot(1,2,2)                                                 #R # Your code here\n",
    "    plt.title('Bitdepth: ' + str(bitDepth))                            #R # Your code here\n",
    "    plt.imshow(linear2sRGB(quantize(sRGB2linear(img_sRGB),bitDepth)))  #R # Your code here\n",
    "    plt.show()                                                         #R # Your code here\n",
    "# What is the nimimun bit-depth that can be used for quantizing the image without artifacts? \n",
    "# Is this the same value for both gradients?s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Dependency of quantization artifact visibility on noise \n",
    "The minimum contrast visibility is highly dependent on noise. Find the needed tonal resolution\n",
    "depending on Gaussian noise before and after quantization.\n",
    "- Create two 1024 pixel wide horizontal ramps, one from 0 to 0.1 and one from 0.5 to 0.6 in sRGB 0…1 domain.\n",
    "- Display this gradient quantized to 8bit.\n",
    "- Find the needed tonal resolution (quantization bit depth) to display this gradient without banding artifacts on your monitor.\n",
    "- Display the image and the gradient adding Gaussian noise with a standard deviation of one 8bit code value (1/255) before quantization. Which bit depth is now needed?\n",
    "- Display the image and the gradient adding Gaussian noise with a standard deviation of one 8bit code value (1/255) after quantization. Which bit depth is now needed?\n",
    "- Explain why adding noise before quantization has a different effect compared to adding noise after quantization.\n",
    "- Simulate the photon shot noise of a typical video camera with a full well capacity of 3000 photons per sensor element and assess the needed tonal resolution (quantization bit depth) for images acquired with such a camera if the sensor would not introduce any additional noise to the photon shot noise you simulated.\n",
    "- Why does the gradient need a different bit-depth compared to the image?\n",
    "- How does this change your assessment of the needed bit-depth for linear RAW-camerafootage from exercise 1.6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create horizontal ramp from 0 to 0.1 and 0.5 to 0.6\n",
    "\n",
    "ramp1 = np.zeros((1, 1024,1))                          #R ramp1 = # Your code here\n",
    "ramp1[0,:,0] = np.linspace(0.5, 0.6, ramp1.shape[1])   #R # Your code here\n",
    "ramp1 = np.tile(ramp1, (100,1,3))                      #R # Your code here\n",
    "\n",
    "ramp2 = np.zeros((1, 1024,1))                          #R ramp2 = # Your code here\n",
    "ramp2[0,:,0] = np.linspace(0.0, 0.1, ramp2.shape[1])   #R # Your code here\n",
    "ramp2 = np.tile(ramp2, (100,1,3))                      #R # Your code here\n",
    "\n",
    "ramp = np.concatenate( ( ramp1, ramp2 ), axis=0 )             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display quantized. Find the needed quantization for display without banding artifacts\n",
    "myBitDepth = 5 # Adjust here\n",
    "\n",
    "# Display\n",
    "plt.figure( figsize = ( 15, 10 ) )\n",
    "plt.title( 'Quantisierung mit '+ str( myBitDepth ) + ' Bit' )\n",
    "plt.imshow( quantize( ramp, myBitDepth  ) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gaussian noise with a standard deviation of one 8bit code value (1/255)\n",
    "# Find the needed quantization for the ramp if this noise is added before quantization\n",
    "\n",
    "# Add noise to the ramp\n",
    "myBitDepth = 5 # Adjust here\n",
    "myNoiseStDevIn8BitCVs = 1\n",
    "\n",
    "# Add noise to ramp\n",
    "randRamp = ramp + (np.random.randn(200, 1024,3)) / (256/myNoiseStDevIn8BitCVs-1) #R randramp = ramp + # Your code here\n",
    "\n",
    "# qunatize Ramp with added noise\n",
    "randRampQuantized = quantize( randRamp, myBitDepth)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title( 'Noise with a StDev of ' + str(myNoiseStDevIn8BitCVs) + ' 8bit CVs, then quantization to '+ str( myBitDepth ) + ' Bit' )\n",
    "plt.imshow( np.clip( randRampQuantized, 0.0, 1.0 ) );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the needed quantization for the ramp if this noise is added after quantization\n",
    "myBitDepth = 5 # Adjust here\n",
    "myNoiseStDevIn8BitCVs = 1\n",
    "\n",
    "# Quantize Ramp\n",
    "quantRamp = quantize( ramp, myBitDepth )\n",
    "\n",
    "# Add noise to already quantized ramp \n",
    "quantAndNoiseRamp = quantRamp + (np.random.randn(200, 1024,3)) / 255 #R quantAndNoiseRamp = # Your code here\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.title( 'Quantization to ' + str( myBitDepth ) + ' Bit, then add Noise with a StDev of ' + str(myNoiseStDevIn8BitCVs) + ' 8bit CVs' )\n",
    "plt.imshow( np.clip( quantAndNoiseRamp, 0.0, 1.0 ) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now simulate a typical video camera with a full well capacity of 10000 photons per sensor element.\n",
    "\n",
    "# Convert img from sRGB to linear\n",
    "img_Linear = sRGB2linear( img_sRGB )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add poisson distibuted photon shot noise assuming white equals 3000 photons\n",
    "# Reference: HPA 2015, 4k-HDR-Imagers, Dr Peter Centen\n",
    "\n",
    "# Add poisson Noise (skimage.util.random_noise) may be useful\n",
    "img_LinearPNoise = skimage.util.random_noise(np.round(img_Linear * 3000)/ 3000, 'poisson', clip=False)  #R img_LinearPNoise = # Your code here\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow( np.clip( linear2sRGB( img_LinearPNoise ), 0.0, 1.0) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out which minimum quantization is needed for lossless display of broadcast imagery\n",
    "myBitDepth = 5 # Adjust here\n",
    "\n",
    "# Qunatize Image with added photon shot noise\n",
    "img_LinearPNoiseQuantized = quantize( img_LinearPNoise, myBitDepth)\n",
    "\n",
    "# Display\n",
    "plt.figure( figsize = (15,10) )\n",
    "plt.title( 'Simulated image from UHD broadcast camera quantized to '+ str( myBitDepth ) + ' Bit' )\n",
    "plt.imshow( np.clip( linear2sRGB( img_LinearPNoiseQuantized ), 0.0, 1.0 ) );      #R plt.imshow(   # Your code here\n",
    "\n",
    "# Explain how these findings change your assessment of the needed bit-depth for\n",
    "# linear RAW camera footage from exercise 1.6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}