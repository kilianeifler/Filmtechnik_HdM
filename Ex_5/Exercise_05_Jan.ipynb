{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 - Image analysis and compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading a few python modules used for image processing, io and plotting\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "from scipy import fftpack\n",
    "import skimage\n",
    "import imageio\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from accum import accum\n",
    "\n",
    "from skimage.transform import resize\n",
    "# for 16 bit PNG support in imageio if needed, imageio.plugins.freeimage.download() might need to be run once per system (or exr/hdr/pgm/ppm support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load our favorite test image\n",
    "peppersImg = imageio.imread('peppers.png')\n",
    "peppersImg = np.float64( peppersImg ) / 255\n",
    "\n",
    "# Create standard 75% color bars with the width of the peppers image and the following height:\n",
    "bars_and_gradient_height = 64\n",
    "\n",
    "colorBar75vals = np.array([[[0, 0, 0], [0, 0, 1], [1, 0, 0], [1, 0, 1], [0, 1, 0], [0, 1, 1], [1, 1, 0], [1, 1, 1]]]) * 0.75\n",
    "colorBar75 = np.tile( colorBar75vals, (bars_and_gradient_height*np.int32(np.size(peppersImg,1)/np.size(colorBar75vals,1)), 1, 1) )\n",
    "colorBar75 = np.reshape( colorBar75, (64,np.size(peppersImg,1),3), order='F' ) #R colorBar75 = # Your code here\n",
    "\n",
    "# Create a gradient from 0...1 with the width of the peppers image and the same height as the color bars\n",
    "gradient = np.tile( np.reshape( np.linspace(0,1,np.size(peppersImg,1)), (1,np.size(peppersImg,1)) )[:,:,np.newaxis], (bars_and_gradient_height, 1, 3) ) #R gradient = # Your code here\n",
    "\n",
    "# Debug shapes to see if they fit\n",
    "print( peppersImg.shape )\n",
    "print( colorBar75.shape )\n",
    "print( gradient.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate and show Image\n",
    "plt.subplot(1,2,1)\n",
    "img = np.concatenate( ( peppersImg, colorBar75, gradient), axis=0 )\n",
    "plt.imshow( img );\n",
    "plt.title(\"Your Image\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow( plt.imread( \"exercise_05_results_for_reference/peppers_bar_gradient.png\" ), interpolation = 'catrom' );\n",
    "plt.title(\"Reference Image\\nwith color bars\\nand gradient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Histogram\n",
    "\n",
    "Histograms are useful to see the distribution of code values between blacks, mid tones and highlights and to eliminate color casts. They can also be used to detect reduced quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the function `calculateHistogramm` by looping over all bins and not using the Python histogram functions.\n",
    "def calculateHistogramm(img, bins = 256, minval = 0.0, maxval = 1.0):\n",
    "    data = img.copy()#R # Your code here\n",
    "    #R # Your code here\n",
    "    data = (data - minval) / (maxval - minval)#R # Your code here\n",
    "    data[data < 0.0] = -1000#R # Your code here\n",
    "    data[data > 1.0] = -1000#R # Your code here\n",
    "    data = np.floor(data * bins)#R # Your code here\n",
    "#R # Your code here\n",
    "    result = np.zeros((bins))#R # Your code here\n",
    "    for i in range(bins):#R # Your code here\n",
    "        result[i] = np.sum(data == i)#R # Your code here\n",
    "#R # Your code here\n",
    "    return result\n",
    "    # The result vector is a 1D-vector with the siye of the number of bins containing the number of pixel values that fall into this bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the ASC-CDL grading controls from 4.2 to get an intuition how the histogram behaves.\n",
    "#R # Your code here\n",
    "#R # Your code here\n",
    "#R # Your code here\n",
    "#R # Your code here\n",
    "gradedImg = img #R gradedImg = # Your code here\n",
    "\n",
    "pepper_hist = calculateHistogramm( gradedImg )\n",
    "hist_range  = np.arange(0, pepper_hist.shape[0])\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(2,2,(1,3))\n",
    "plt.imshow( gradedImg )\n",
    "plt.subplot(2,2,2)\n",
    "img = np.concatenate( ( peppersImg, colorBar75, gradient), axis=0 )\n",
    "plt.bar(hist_range, pepper_hist);\n",
    "plt.title(\"Your Histogram\")\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow( plt.imread( \"exercise_05_results_for_reference/histogram.png\" ), interpolation = 'catrom' );\n",
    "plt.axis('off')\n",
    "plt.title(\"Reference Histogram if no grading is applied\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Play with the histogram resolution to detect that peppers.png seems to be 8 bits.\n",
    "# Increasing the number of bins is one way to do this, but setting minval and maxval to appropriate numbers may be more clever. \n",
    "n_bins = 512#R # Your code here\n",
    "hist_range  = np.arange(0, n_bins)#R # Your code here\n",
    "f = plt.figure(figsize=(20, 6)) #R # Your code here\n",
    "a = f.subplots() #R # Your code here\n",
    "color = ['red', 'green', 'blue'] #R # Your code here\n",
    "for i in range(3): #R # Your code here\n",
    "    pepper_hist = calculateHistogramm(img[..., i], bins=n_bins) #R # Your code here\n",
    "    a.bar(hist_range, pepper_hist, color=color[i]) #R # Your code here\n",
    "plt.show() #R # Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to hide the fact that peppers.png is only 8bits by resizing it.\n",
    "# What may be a better choice than resizing? Would this solve visible quantization artifacts in the image?\n",
    "pepper_hist = calculateHistogramm(img[:,:,2], minval=0.3, maxval=0.5) #R # Your code here\n",
    "hist_range  = np.arange(0, pepper_hist.shape[0]) #R # Your code here\n",
    "plt.figure(figsize=(15,5)) #R # Your code here\n",
    "plt.bar(hist_range, pepper_hist); #R # Your code here\n",
    "\n",
    "img_scaled = resize(img, (520,520))\n",
    "\n",
    "pepper_hist = calculateHistogramm(img_scaled[:,:,2], minval=0.3, maxval=0.5 ) #R # Your code here\n",
    "hist_range  = np.arange(0, pepper_hist.shape[0]) #R # Your code here\n",
    "fig = plt.figure(figsize=(15,5)) #R # Your code here\n",
    "ax = fig.subplots() #R # Your code here\n",
    "ax.bar(hist_range, pepper_hist) #R # Your code here\n",
    "ax.set_yscale('log') #R # Your code here\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pepper_hist = calculateHistogramm(img[:,:,2], minval=0.3, maxval=0.4 ) #R # Your code here\n",
    "hist_range  = np.arange(0, pepper_hist.shape[0]) #R # Your code here\n",
    "plt.figure(figsize=(15,5)) #R # Your code here\n",
    "plt.bar(hist_range, pepper_hist); #R # Your code here\n",
    "\n",
    "img_noise = img + np.random.randn( img.shape[0], img.shape[1], img.shape[2] ) / 255\n",
    "\n",
    "pepper_hist = calculateHistogramm(img_noise[:,:,2], minval=0.3, maxval=0.4 ) #R # Your code here\n",
    "hist_range  = np.arange(0, pepper_hist.shape[0]) #R # Your code here\n",
    "fig = plt.figure(figsize=(15,5)) #R # Your code here\n",
    "ax = fig.subplots() #R # Your code here\n",
    "ax.bar(hist_range, pepper_hist) #R # Your code here\n",
    "ax.set_yscale('log') #R # Your code here\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Waveform\n",
    "\n",
    "A waveform monitor can be thought as being histogram per column, but the height of the histogram bar is now shown as pixel intensity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the function `calculateWaveform`.\n",
    "def calculateWaveform(img, bins = 256, luma = False, minval = 0.0, maxval = 1.0):\n",
    "    if not (luma and img.ndim == 3) and not (not luma and img.ndim >= 2 and img.ndim <= 3):\n",
    "        raise Exception('Invalid input dimensions or luma conversion requested on 2D image')\n",
    "\n",
    "    data = img.copy()\n",
    "    if luma and len(data.shape) == 3:\n",
    "        data = 0.2126 * img[..., 0] + 0.7152 * img[..., 1] + 0.0722 * img[..., 2]\n",
    "    luma = data.ndim == 2 # in case a 2D image has been imported\n",
    "    \n",
    "    data = (data - minval) / (maxval - minval)\n",
    "    data[data < 0.0] = 0.0\n",
    "    data[data > 1.0] = 1.0\n",
    "    data = np.floor(data * (bins - 0.000001))\n",
    "\n",
    "    dimensions = (bins, data.shape[1])\n",
    "    if not luma:\n",
    "        dimensions = (dimensions[0], dimensions[1], data.shape[2])\n",
    "\n",
    "    result = np.zeros(dimensions)\n",
    "    for i in range(bins):\n",
    "        result[i, ...] = np.sum(data == i, axis=0)\n",
    "    result = np.log(result + 1) / np.log(bins)\n",
    "\n",
    "    return np.flip(result, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the grading controls from 4.2 and get an intuition how the waveform behaves.\n",
    "#R # Your code here\n",
    "#R # Your code here\n",
    "#R # Your code here\n",
    "#R # Your code here\n",
    "gradedImg = img #R gradedImg = # Your code here\n",
    "\n",
    "wf = calculateWaveform(gradedImg, bins=256)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow( np.concatenate( ( gradedImg, wf), axis=0 ) );\n",
    "plt.title(\"Your image\");\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow( plt.imread( \"exercise_05_results_for_reference/img_and_waveform.png\" ), interpolation = 'catrom' );\n",
    "plt.axis('off')\n",
    "plt.title(\"Reference Image and Waveform\\nif no grading is applied\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the bins to 512. How can you detect limited tonal resolution using a waveform? Did you already observe this in grading?\n",
    "wf = calculateWaveform(gradedImg, bins=512)\n",
    "# plt.figure(figsize=(10,20)) # You may need to enlarge the plot to see the effect...\n",
    "plt.imshow( np.concatenate( ( gradedImg, wf), axis=0 ) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Vectorscope\n",
    "Colorist often use the vectorscope to adjust color balance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the function `calculateVectorscope`.\n",
    "# Hint: For calculating the 2D histogram ‘accum’ will be much faster compared to two loops\n",
    "def calculateVectorscope(img, bins=256):\n",
    "    if img.ndim < 2 or img.shape[-1] != 3:\n",
    "        raise Exception('Invalid input size')\n",
    "\n",
    "    RGB2YCbCr709Mx = np.array([[0.2126, -0.114572, 0.5], [0.7152, -0.385428, -0.454153], [0.0722, 0.5, -0.045847]])\n",
    "    data = img.reshape(-1, 3)\n",
    "    data = np.matmul(data, RGB2YCbCr709Mx)\n",
    "\n",
    "    data = data + 0.5\n",
    "    data[data < 0.0] = 0.0\n",
    "    data[data > 1.0] = 1.0\n",
    "    data = np.uint32(np.floor(data * (bins - 0.000001)))\n",
    "\n",
    "    result = accum(data[:,1:], np.ones((data.shape[0])), size=(bins, bins))\n",
    "    result = np.swapaxes(result, 0, 1)\n",
    "    return np.flip(result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some noise to the image before feeding it into the vectorscope so that the color bars do not only end up at the same pixel position.\n",
    "noise_img = img + (np.random.randn(img.shape[0], img.shape[1], 3) - 0.5) / 256\n",
    "\n",
    "vectorscopeOutput = calculateVectorscope( noise_img )\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.log2(vectorscopeOutput + 1) / np.log2(np.amax( vectorscopeOutput ) + 1), cmap='gray', vmin=0, vmax=1.0)\n",
    "plt.title(\"Your Vectorscope\");\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow( plt.imread( \"exercise_05_results_for_reference/vectorscope.png\" ), interpolation = 'catrom' );\n",
    "plt.axis('off')\n",
    "plt.title(\"Reference Vectorscope\\nif no grading is applied\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the grading controls from 4.2 and get an intuition how the vectorscope behaves. Especially try saturation\n",
    "#R # Your code here\n",
    "#R # Your code here\n",
    "#R # Your code here\n",
    "#R # Your code here\n",
    "gradedImg = img #R gradedImg = # Your code here\n",
    "#R gradedImg = # Your code here\n",
    "foo = calculateVectorscope(noise_img)#R gradedImg = # Your code here\n",
    "plt.figure(figsize=(15,10))#R gradedImg = # Your code here\n",
    "plt.imshow(np.log2(foo + 1) / np.log2(np.amax( foo ) + 1), cmap='gray', vmin=0, vmax=1.0)#R gradedImg = # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Decorelation Color Space/perception\n",
    "\n",
    "The lower spatial resolution of the human visual system for color compared to achromatic structures can be exploited by storing color with less spatial resolution compared to luminance. This process is called color subsampling.\n",
    "\n",
    "**How to transform R’G’B’ signals to be able to apply color subsampling? Luma and chroma need to be separated!**\n",
    "\n",
    "* Transform the image `ct_kiste.jpg` from sRGB to Rec.709 Y’CbCr and back to sRGB. Hint: Search for the original Rec.709 specification https://www.itu.int/rec/R-REC-BT.709-6-201506-I/en.\n",
    "* Apply a Gaussian blur filter with different radius in Y’ in the Rec.709 Y’CbCr domain.\n",
    "* Apply a Gaussian blur filter with different radius in Cb and Cr in the Rec.709 Y’CbCr domain.\n",
    "* What maximum Gaussian blur radius is acceptable in Y’ what maximum radius is acceptable in CbCr?\n",
    "* Give at least two examples why subsampling should only be used in image distribution but not in image acquisition and contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyColorMatrix(values, mat):\n",
    "    tmp = values.reshape(-1, 3)\n",
    "    tmp = np.matmul(tmp, mat)\n",
    "    return np.reshape(tmp, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB2YCbCr709Mx = np.array([[0.2126, -0.114572, 0.5], [0.7152, -0.385428, -0.454153], [0.0722, 0.5, -0.045847]])\n",
    "YCbCr2RGB709Mx = np.linalg.inv(RGB2YCbCr709Mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ycbcr = applyColorMatrix(img, RGB2YCbCr709Mx)\n",
    "\n",
    "ycbcr[:,:,0] = ndimage.gaussian_filter(ycbcr[:,:,0], 0.2)\n",
    "ycbcr[:,:,1] = ndimage.gaussian_filter(ycbcr[:,:,1], 2.5)\n",
    "ycbcr[:,:,2] = ndimage.gaussian_filter(ycbcr[:,:,2], 2.5)\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "plt.imshow(applyColorMatrix(ycbcr, YCbCr2RGB709Mx));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Image compression\n",
    "\n",
    "How can we reduce image file size without reducing spatial or tonal resolution? By reducing quantization in frequency domain instead of spatial domain.\n",
    "* Read peppers.png and convert to 0…1 domain.\n",
    "* Calculate luma for the peppers image and plot this image.\n",
    "* Convert each 8x8 block of this image to frequency domain using the MATLAB functions ‘blockproc’ and ‘dct2’.\n",
    "* Plot the image in frequency domain.\n",
    "* Convert back to spatial domain using blockproc again and idct2.\n",
    "* Make sure there are no roundtrip errors by subtracting the original image from the reconstructed image. The mean absolute difference should be below 10-14.\n",
    "* We will use the JPEG quantization matrix as supplied in the .m file and a QP of 2.7 to reduce the energy of the high frequency DCT coefficients. Perform an elementwise multiplication of each block of the image in frequency domain by the quantization matrix.\n",
    "* The supplied code helps you to find the needed maximum bits needed to encode each block position for this image. You should end up with a number below 64 bits per block.\n",
    "* Now let’s decode again. First multiply each block position by the quantization matrix to rescale these values again.\n",
    "* Convert back from frequency domain to spatial domain.\n",
    "* Plot original image, DCT image and reconstructed image.\n",
    "* Alternatively quantize the original image to 1bit per pixel get down to 64 bits per block.\n",
    "* Scale the image to half the horizontal and vertical size to be able to spend 4 bits per pixel.\n",
    "* Scale the image to the exact size so that each pixel can use 8bits, but the needed file size stays the same as for the images that only used 64 bits per block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luma = applyColorMatrix(img, RGB2YCbCr709Mx)[:,:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odct2(a):\n",
    "    return fftpack.dct(fftpack.dct(a, axis=0, norm='ortho' ), axis=1, norm='ortho')\n",
    "def idct2(a):\n",
    "    return fftpack.idct(fftpack.idct(a, axis=0 , norm='ortho'), axis=1 , norm='ortho')\n",
    "\n",
    "def blockProc(data, blockfunc):\n",
    "    result = np.zeros(data.shape)\n",
    "\n",
    "    #for y in range(data.shape[0]//8):  ## Umbauen auf range(0, dct_image.shape[0], 8)\n",
    "    #    for x in range(data.shape[1]//8):\n",
    "    for y in range(0, data.shape[0], 8):\n",
    "        for x in range(0, data.shape[1], 8):\n",
    "            block = data[y:y+8, x:x+8]\n",
    "            block = blockfunc(block)\n",
    "            result[y:y+8, x:x+8] = block\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_img = blockProc(luma, odct2)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(dct_img, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idct_img = blockProc(dct_img, idct2)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(dct_img, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = luma - idct_img\n",
    "print(np.amin(diff), np.amax(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qMatrix = np.array([[16,  11,  10,  16,  24,   40,   51,   61],\n",
    "                    [12,  12,  14,  19,  26,   58,   60,   55],\n",
    "                    [14,  13,  16,  24,  40,   57,   69,   56],\n",
    "                    [14,  17,  22,  29,  51,   87,   80,   62],\n",
    "                    [18,  22,  37,  56,  68,  109,  103,   77],\n",
    "                    [24,  35,  55,  64,  81,  104,  113,   92],\n",
    "                    [49,  64,  78,  87, 103,  121,  120,  101],\n",
    "                    [72,  92,  95,  98, 112,  100,  103,   99]])\n",
    "qp = 2.7\n",
    "qmat_q = qMatrix * qp\n",
    "qmat_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_qm = blockProc(luma, lambda x : np.divide(odct2(x), qmat_q))\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(dct_qm, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round and quantize\n",
    "dct_rounded = np.round(dct_qm * 255) / 255\n",
    "\n",
    "idct_qm = blockProc(dct_rounded, lambda x : idct2(np.multiply(x, qmat_q)))\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(idct_qm, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = idct_qm - luma\n",
    "print(np.amin(diff), np.amax(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "checkers = np.zeros((320,240), dtype=np.uint8)\n",
    "checkers[::2,::2] = 255\n",
    "checkers[1::2,1::2] = 255\n",
    "\n",
    "plt.imshow(checkers, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}