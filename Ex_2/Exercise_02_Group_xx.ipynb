{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Number: xx\n",
    "# Group Members: xx xx, yy yy, (zz zz) \n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import numpy.matlib as ml\n",
    "import imageio\n",
    "import skimage\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "## 2.1 Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a frequency sweep from 0.001Hz to 10Hz per Pixel width\n",
    "\n",
    "# Init some x values\n",
    "x = np.arange(1,1001)\n",
    "\n",
    "# Evaluate our sweep function at position 'x'\n",
    "def evalSweep(x):\n",
    "     return np.sin( -np.pi * np.power( 2, 1-(150-x) / 250 ) * np.power( 5, (-150+x)/250 ) / np.log(10) )\n",
    "     \n",
    "# Calculate and plot y values for sine sweep\n",
    "y = evalSweep(x)\n",
    "plt.plot(x,y,\".-\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next create pattern as above as an image\n",
    "\n",
    "# We simulate a camera with an indefinitively small fill-factor and therefore calculate the value for each pixel by sampling the frequency sweep only in the middle of the pixel.\n",
    "imgHeight = 100\n",
    "imgWidth = 1000\n",
    "\n",
    "xImg = np.reshape( np.arange(0,imgWidth), (1,imgWidth) ) + np.reshape( np.linspace(0,1,imgHeight),(imgHeight,1) )\n",
    "\n",
    "# Calculate y values for sine sweep. Use evalSweep and remember to corectly normalize the sine\n",
    "yImg = # your code here\n",
    "\n",
    "plt.title('Fixed sampling at pixel center')\n",
    "plt.imshow(yImg, cmap='gray', vmin=0.0, vmax=1.0);\n",
    "\n",
    "# Where do the weird pattern right of pixel 500 come from?\n",
    "# \n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create the same 2D image but sample at a random position inside each pixel\n",
    "xRandImg = xImg +  # your code here\n",
    "yRandImg =         # your code here\n",
    "plt.title('Random sampling position inside pixel')\n",
    "plt.imshow( yRandImg, cmap='gray', vmin=0.0, vmax=1.0)\n",
    "\n",
    "# What happened to the weird pattern in the high frequencies?\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's sample the full pixelsize via monte carlo sampling (sample the value for each pixel at a random position inside the pixel)\n",
    "# Put the number of samples in the third dimension (axis=2)\n",
    "# Then calculate the mean of all samples.\n",
    "# Simulate a fill factor of 50% and 25% by only sampling the respective area per pixel. The fill factor describes the area of the pixel that is sensitive to light and not covered by metal layers.\n",
    "\n",
    "# Add a third dimension\n",
    "xImg = np.reshape( xImg, (imgHeight,imgWidth,1))\n",
    "\n",
    "for nSamples in [1, 8, 64, 256, 1024]: # Comment out 256 and 1024 for debugging. Add 2048, 4096 or 8192 if your computer has enough RAM and you want noise-free images (-:\n",
    "    start=time.time()\n",
    "\n",
    "    # Fill factor 25%\n",
    "    xRandImg = xImg +    # your code here\n",
    "    yRandImgFF25 =       # your code here. Hint: Use \"np.mean( ... , axis=2)\" to sum along the third dimension \n",
    "\n",
    "    # Fill factor 50%\n",
    "    xRandImg = xImg +    # your code here\n",
    "    yRandImgFF50 =       # your code here. Hint: Use \"np.mean( ... , axis=2)\" to sum along the third dimension \n",
    "\n",
    "    # Fill factor 100%\n",
    "    xRandImg = xImg +    # your code here\n",
    "    yRandImgFF100 =      # your code here. Hint: Use \"np.mean( ... , axis=2)\" to sum along the third dimension \n",
    "\n",
    "    # Show\n",
    "    plt.title('Monte Carlo sampling with ' + str(nSamples) + ' samples.\\nBox filter, fill factor 25%, 50% and 100%')\n",
    "    plt.imshow(np.concatenate((yRandImgFF25, np.zeros((10,x.shape[0])), yRandImgFF50, np.zeros((10,x.shape[0])), yRandImgFF100) , axis=0), cmap='gray', vmin=0.0, vmax=1.0)\n",
    "    plt.show()\n",
    "    ende=time.time()\n",
    "    print('Calculating ' + str(nSamples) + ' samples took ' + str(ende-start) + ' seconds')\n",
    "    # Pause for a second before calculating the next image\n",
    "\n",
    "# Can the weird patterns in the high frequencies be completely removed by a large fill factor?\n",
    "#\n",
    "#\n",
    "#\n",
    "# Bonus question for experts on the human visual system: Why are the small weird pattern only visible with 1024 samples and more?\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add a gaussian blur OLPF filter to a typical fill factor of 50% simulation by adding monte carlo sampling with a gaussian distribution ('randn').\n",
    "\n",
    "for nSamples in [1, 8, 64, 256, 1024]: # Comment out 256 and 1024 for debugging. Add 2048, 4096 or 8192 if your computer has enough RAM and you want noise-free images (-:\n",
    "    start = time.time()\n",
    "\n",
    "    # OLPF filter with a StDev of 0.25 pixels\n",
    "    xRandImg = xImg +    # your code here\n",
    "    yRandImgStD025 =     # your code here\n",
    "\n",
    "    # OLPF filter with a StDev 0.5 pixels\n",
    "    xRandImg = xImg +    # your code here\n",
    "    yRandImgStD05  =     # your code here\n",
    "\n",
    "    # OLPF filter with a StDev 0.7 pixels\n",
    "    xRandImg = xImg +    # your code here\n",
    "    yRandImgStD07 =      # your code here\n",
    "\n",
    "    # OLPF filter with a StDev 1 pixels\n",
    "    xRandImg = xImg +    # your code here\n",
    "    yRandImgStD100 =     # your code here\n",
    "    # Show\n",
    "    plt.title('Monte Carlo sampling with ' + str(nSamples) + ' samples, fill factor of 50%\\n and a gaussian distribution OLPF with a stDev of 0.25, 0.5, 0.7 and 1')\n",
    "    plt.imshow(np.concatenate((yRandImgStD025, yRandImgStD05, yRandImgStD07, yRandImgStD100), axis=0 ), cmap='gray', vmin=0.0, vmax=1.0)\n",
    "    plt.show()\n",
    "    ende=time.time()\n",
    "    print('Calculating ' + str(nSamples) + ' samples took ' + str(ende-start) + ' seconds')\n",
    "\n",
    "# What OLPF-Filter would you choose if the artifacys need to be avoided at any cost? What would be a real-world candidate?\n",
    "#\n",
    "#\n",
    "#\n",
    "# Why do some modern cameras like the Nikon D850 not use an OLPF filter anymore? \n",
    "#\n",
    "#\n",
    "#\n",
    "# In which cases would you prefer to have an OLPF filter, even with a high resolution camera like the Nikon D850\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Demosaicing\n",
    "During the lecture we have learned about different color architectures. The most common one is the\n",
    "‚ÄòBayer‚Äô Pattern. If you want to generate Pixels with the full RGB information you could take on red\n",
    "pixel (R), one blue Pixel (B) and the mean between the two corresponding green pixels (G1,G2). This\n",
    "results in ¬º the number of pixels or half the resolution of the original sensor. You can also generate\n",
    "values for the missing two channels by interpolation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the true resolution of a Bayer pattern sensor based on your knowledge about human vision. Find arguments for both, ARRI‚Äôs approach with the ALEXA and Canon‚Äôs approach with the original C300.\n",
    "#\n",
    "#\n",
    "#\n",
    "# Why do motion picture cameras often use oversampling opposed to still cameras?\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 RAW Data Processing\n",
    "Download the files Haus_01.tiff ‚Äì Haus_07.tiff. They show the same scene but with different exposures. The TIFF files have been created by reading the RAW data from a Canon 5DMkII DSLR by using dcraw:\n",
    "\n",
    "dcraw -4 -D -T /SomePath/IMG_XXXX.CR2\n",
    "\n",
    "Dcraw copies the 14bit raw code values into the 14 least significant bits of the 16bit TIFF file and pads the two most significant bits with zeros.\n",
    "\n",
    "Read all files into MATLAB.\n",
    "DeBayer all images by integrating four sensor elements (R, G1, G2, B) into one RGB pixel.\n",
    "Look at the histogram (imhist) for the individual color channels to estimate the black value. Hint: the black level is a number of the form: 2!, ùëõ ‚àà ‚Ñï!.\n",
    "Subtract the black level from all images.\n",
    "Why do cameras store RAW images with an elevated black level?\n",
    "Display the images by using the correct de-linearization for your monitor and play with exposure and white balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TIFFs into 3D array(gray-value image):\n",
    "rawImg = np.stack( [ imageio.imread('Exercise_02_Haus_0' + str(i) + '.tiff') [...,np.newaxis] for i in range(1,8) ], axis=3)\n",
    "\n",
    "rawImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract four channels r, g1, g2  and b\n",
    "c1 = rawImg[0::2,0::2,:,:]\n",
    "c2 = rawImg[1::2,0::2,:,:]\n",
    "c3 = rawImg[0::2,1::2,:,:]\n",
    "c4 = rawImg[1::2,1::2,:,:]\n",
    "\n",
    "# Find out which two channels are green ?\n",
    "# Your code here\n",
    "# Your code here\n",
    "# Your code here\n",
    "# Your code here\n",
    "# Your code here\n",
    "# Your code here\n",
    "# Your code here\n",
    "# Your code here\n",
    "# Your code here\n",
    "\n",
    "rgbImg.shape\n",
    "\n",
    "# Plot one of the images\n",
    "plt.imshow( np.fmax( 0.0, np.fmin(1.0, linear2sRGB( rgbImg[:,:,:,3] / (2**14) ) ) ) )\n",
    "\n",
    "# Does this look good? If not, why?\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now implement the sRGB functions so that we can use them to convert our image to linear domain\n",
    "def linear2sRGB(x):\n",
    "    # Your code here\n",
    "    # Your code here\n",
    "    # Your code here\n",
    "    return result\n",
    "\n",
    "def sRGB2linear(x):\n",
    "    # Your code here\n",
    "    # Your code here\n",
    "    # Your code here\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram is one possibility to find the black offset. do you have other ideas?\n",
    "\n",
    "tmp = plt.hist(rgbImg[::8,::8,0,0])\n",
    "plt.show()\n",
    "\n",
    "tmp2 = plt.hist(rgbImg[::8,::8,0,0])\n",
    "plt.show()\n",
    "\n",
    "temp3 = plt.hist(rgbImg[::8,::8,0,0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substract Black and normalize white\n",
    "rgbImg = # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all exposures.\n",
    "# What looks better now?\n",
    "# What still looks wrong?\n",
    "exposure = 1\n",
    "\n",
    "for ii in range(7):\n",
    "    plt.subplot(1,7,ii+1)\n",
    "    plt.imshow( np.fmax( 0.0, np.fmin(1.0,linear2sRGB( rgbImg[:,:,:,ii] * exposure ) ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure = 0.3\n",
    "# exposure = 32  \n",
    "# Look at a detail of the image.\n",
    "# Play with exposure to examine the exposure stack. \n",
    "# Which image does provide less noise in the blacks? What is missing in this image?\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "for ii in range(7):\n",
    "    plt.subplot(1,7,ii+1)\n",
    "    plt.imshow( np.fmax( 0.0, np.fmin(1.0, linear2sRGB( rgbImg[200:2800,700:1300,:,ii] * exposure ) ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbImg.shape # Shape should be (2591, 1722, 3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for the next exercise\n",
    "np.save('rgb_exposure_stack.npmat', rgbImg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}